{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_hash</th>\n",
       "      <th>drug</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2e180be4c9214c1f5ab51fd8cc32bc80c9f612e0</td>\n",
       "      <td>gilenya</td>\n",
       "      <td>2</td>\n",
       "      <td>autoimmune diseases tend to come in clusters. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9eba8f80e7e20f3a2f48685530748fbfa95943e4</td>\n",
       "      <td>gilenya</td>\n",
       "      <td>2</td>\n",
       "      <td>i can completely understand why you would want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fe809672251f6bd0d986e00380f48d047c7e7b76</td>\n",
       "      <td>fingolimod</td>\n",
       "      <td>2</td>\n",
       "      <td>interesting that it only targets s1p - 1 / 5 r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bd22104dfa9ec80db4099523e03fae7a52735eb6</td>\n",
       "      <td>ocrevus</td>\n",
       "      <td>2</td>\n",
       "      <td>very interesting ,  grand merci. now i wonder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b227688381f9b25e5b65109dd00f7f895e838249</td>\n",
       "      <td>gilenya</td>\n",
       "      <td>1</td>\n",
       "      <td>hi everybody ,  my latest mri results for brai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                unique_hash                        ...                                                                       text\n",
       "0  2e180be4c9214c1f5ab51fd8cc32bc80c9f612e0                        ...                          autoimmune diseases tend to come in clusters. ...\n",
       "1  9eba8f80e7e20f3a2f48685530748fbfa95943e4                        ...                          i can completely understand why you would want...\n",
       "2  fe809672251f6bd0d986e00380f48d047c7e7b76                        ...                          interesting that it only targets s1p - 1 / 5 r...\n",
       "3  bd22104dfa9ec80db4099523e03fae7a52735eb6                        ...                          very interesting ,  grand merci. now i wonder ...\n",
       "4  b227688381f9b25e5b65109dd00f7f895e838249                        ...                          hi everybody ,  my latest mri results for brai...\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('../input/av-hacks/train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cucco\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/a4/885b87757c0dabb87b6fa7f7ea214f33c03d6159aa4bcd7d7024f07839e5/cucco-2.2.1.tar.gz (51kB)\r\n",
      "\u001b[K     |████████████████████████████████| 51kB 3.9MB/s \r\n",
      "\u001b[?25hBuilding wheels for collected packages: cucco\r\n",
      "  Building wheel for cucco (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/1b/9f/88/4601c19912235677fd8fa8a2958cae82dcc63a1d8672633e29\r\n",
      "Successfully built cucco\r\n",
      "Installing collected packages: cucco\r\n",
      "Successfully installed cucco-2.2.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install cucco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cucco\n",
    "from cucco import Cucco\n",
    "\n",
    "norm_en = Cucco()\n",
    "\n",
    "def normalise(row):\n",
    "    ''' Performs text normalisation for multiple languages. Removes stopwords,punctuation etc.'''\n",
    "    \n",
    "    text = row['text']\n",
    "    sents = nltk.sent_tokenize(text)\n",
    "    rules = ['remove_stop_words', 'replace_punctuation', 'remove_extra_whitespaces']\n",
    "    norm_text = ' '.join([norm_en.normalize(sent,rules) for sent in sents])\n",
    "    \n",
    "    return norm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['text'] = data.apply(normalise,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 21903)\t1\n",
      "  (0, 15631)\t1\n",
      "  (0, 17455)\t1\n",
      "  (0, 7596)\t1\n",
      "  (0, 6165)\t1\n",
      "  (0, 11201)\t1\n",
      "  (0, 6156)\t1\n",
      "  (0, 22099)\t1\n",
      "  (0, 13421)\t1\n",
      "  (0, 21407)\t1\n",
      "  (0, 5100)\t1\n",
      "  (0, 6890)\t1\n",
      "  (0, 19708)\t1\n",
      "  (0, 2285)\t1\n",
      "  (0, 20755)\t1\n",
      "  (0, 19795)\t1\n",
      "  (0, 7568)\t1\n",
      "  (0, 20226)\t1\n",
      "  (0, 21599)\t1\n",
      "  (0, 4530)\t1\n",
      "  (0, 9258)\t1\n",
      "  (0, 8273)\t2\n",
      "  (0, 9122)\t1\n",
      "  (0, 4962)\t1\n",
      "  (0, 19969)\t1\n",
      "  :\t:\n",
      "  (5278, 6130)\t1\n",
      "  (5278, 13154)\t1\n",
      "  (5278, 15994)\t1\n",
      "  (5278, 20112)\t1\n",
      "  (5278, 13985)\t1\n",
      "  (5278, 9581)\t1\n",
      "  (5278, 17519)\t1\n",
      "  (5278, 14516)\t1\n",
      "  (5278, 13153)\t1\n",
      "  (5278, 5583)\t1\n",
      "  (5278, 14247)\t1\n",
      "  (5278, 6039)\t1\n",
      "  (5278, 16149)\t1\n",
      "  (5278, 13510)\t2\n",
      "  (5278, 19219)\t1\n",
      "  (5278, 22103)\t1\n",
      "  (5278, 9678)\t1\n",
      "  (5278, 17005)\t1\n",
      "  (5278, 14365)\t1\n",
      "  (5278, 15186)\t1\n",
      "  (5278, 4827)\t1\n",
      "  (5278, 7088)\t2\n",
      "  (5278, 19795)\t1\n",
      "  (5278, 9258)\t1\n",
      "  (5278, 19969)\t1\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "cv = CountVectorizer(max_df=0.95,min_df=2,stop_words='english')\n",
    "term_matrix = cv.fit_transform(data['text'])\n",
    "print(term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 22233)\n"
     ]
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=5)\n",
    "lda.fit(term_matrix)\n",
    "\n",
    "len(lda.components_)\n",
    "print(lda.components_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 38.46065252 167.64559662   1.36158083 ...   0.20000001   2.85466912\n",
      "    0.20041186]\n",
      " [ 10.31586945  60.71878136   0.2000006  ...   0.20000002   0.20055915\n",
      "    0.20000015]\n",
      " [ 33.33358364  82.69113299   0.20000055 ...   0.20000002   0.20000033\n",
      "    0.20000014]\n",
      " [  0.20295818   6.77537267   0.20000054 ...   0.20101518   0.20000032\n",
      "    0.20000014]\n",
      " [ 19.68693621  59.16911636   1.03841749 ...   2.19898478   3.54477108\n",
      "    3.19958771]]\n"
     ]
    }
   ],
   "source": [
    "print(lda.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22233\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(lda.components_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "health\n",
      "sclerosis\n",
      "people\n",
      "drug\n",
      "multiple\n",
      "study\n",
      "disease\n",
      "treatment\n",
      "patients\n",
      "ms\n"
     ]
    }
   ],
   "source": [
    "topic = lda.components_[0]\n",
    "top_words_indices = topic.argsort()[-10:]\n",
    "for index in top_words_indices:\n",
    "    print(cv.get_feature_names()[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words for topic 0\n",
      "['health', 'sclerosis', 'people', 'drug', 'multiple', 'study', 'disease', 'treatment', 'patients', 'ms']\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Top words for topic 1\n",
      "['months', 'brain', 'egfr', 'tarceva', 'nsclc', 'chemo', 'stage', 'treatment', 'lung', 'cancer']\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Top words for topic 2\n",
      "['ocrevus', 'people', 'things', 'work', 'life', 'feel', 'years', 'day', 'good', 'time']\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Top words for topic 3\n",
      "['dose', 'disease', 'symptoms', 'crohn', 'blood', 'remicade', 'humira', 'pain', 'effects', 'doctor']\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Top words for topic 4\n",
      "['tumor', 'study', 'cell', 'clinical', 'disease', 'cells', 'therapy', 'treatment', 'cancer', 'patients']\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "topic_word_dict = {}\n",
    "for index,topic in enumerate(lda.components_):\n",
    "    words = [cv.get_feature_names()[i] for i in topic.argsort()[-10:]]\n",
    "    topic_word_dict[index] = words\n",
    "    print('Top words for topic {}'.format(index))\n",
    "    print(words)\n",
    "    print('-'*120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = lda.transform(term_matrix)\n",
    "data['topic'] = topics.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_topics(row):\n",
    "    topic = row['topic']\n",
    "    words = topic_word_dict[topic]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                unique_hash                        ...                                                                topic words\n",
      "0  2e180be4c9214c1f5ab51fd8cc32bc80c9f612e0                        ...                          [ocrevus, people, things, work, life, feel, ye...\n",
      "1  9eba8f80e7e20f3a2f48685530748fbfa95943e4                        ...                          [health, sclerosis, people, drug, multiple, st...\n",
      "2  fe809672251f6bd0d986e00380f48d047c7e7b76                        ...                          [tumor, study, cell, clinical, disease, cells,...\n",
      "3  bd22104dfa9ec80db4099523e03fae7a52735eb6                        ...                          [health, sclerosis, people, drug, multiple, st...\n",
      "4  b227688381f9b25e5b65109dd00f7f895e838249                        ...                          [health, sclerosis, people, drug, multiple, st...\n",
      "\n",
      "[5 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "data['topic words'] = data.apply(assign_topics,axis=1)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_hash</th>\n",
       "      <th>drug</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>topic words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2e180be4c9214c1f5ab51fd8cc32bc80c9f612e0</td>\n",
       "      <td>gilenya</td>\n",
       "      <td>2</td>\n",
       "      <td>autoimmune diseases tend clusters gilenya    f...</td>\n",
       "      <td>2</td>\n",
       "      <td>[ocrevus, people, things, work, life, feel, ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9eba8f80e7e20f3a2f48685530748fbfa95943e4</td>\n",
       "      <td>gilenya</td>\n",
       "      <td>2</td>\n",
       "      <td>completely understand it   results reported le...</td>\n",
       "      <td>0</td>\n",
       "      <td>[health, sclerosis, people, drug, multiple, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fe809672251f6bd0d986e00380f48d047c7e7b76</td>\n",
       "      <td>fingolimod</td>\n",
       "      <td>2</td>\n",
       "      <td>interesting targets s1p  1  5 receptors 1  5 f...</td>\n",
       "      <td>4</td>\n",
       "      <td>[tumor, study, cell, clinical, disease, cells,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bd22104dfa9ec80db4099523e03fae7a52735eb6</td>\n",
       "      <td>ocrevus</td>\n",
       "      <td>2</td>\n",
       "      <td>interesting   grand merci lemtrada ocrevus sal...</td>\n",
       "      <td>0</td>\n",
       "      <td>[health, sclerosis, people, drug, multiple, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b227688381f9b25e5b65109dd00f7f895e838249</td>\n",
       "      <td>gilenya</td>\n",
       "      <td>1</td>\n",
       "      <td>latest mri results brain cervical cord neuro...</td>\n",
       "      <td>0</td>\n",
       "      <td>[health, sclerosis, people, drug, multiple, st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                unique_hash                        ...                                                                topic words\n",
       "0  2e180be4c9214c1f5ab51fd8cc32bc80c9f612e0                        ...                          [ocrevus, people, things, work, life, feel, ye...\n",
       "1  9eba8f80e7e20f3a2f48685530748fbfa95943e4                        ...                          [health, sclerosis, people, drug, multiple, st...\n",
       "2  fe809672251f6bd0d986e00380f48d047c7e7b76                        ...                          [tumor, study, cell, clinical, disease, cells,...\n",
       "3  bd22104dfa9ec80db4099523e03fae7a52735eb6                        ...                          [health, sclerosis, people, drug, multiple, st...\n",
       "4  b227688381f9b25e5b65109dd00f7f895e838249                        ...                          [health, sclerosis, people, drug, multiple, st...\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  latest mri results brain cervical cord neurologist appointment couple weeks  lesions brain  cord relapses gilenya good sign line cervical cord review concerned me      lesions c2  3 t2 show hypointensity post gadolinium t1 images only represent artifact early axonal loss  bothersome read kind symptoms c2  c3 lesion aware   result change dmt   thanks\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "0\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "['health', 'sclerosis', 'people', 'drug', 'multiple', 'study', 'disease', 'treatment', 'patients', 'ms']\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(data['text'][4])\n",
    "print('-'*120)\n",
    "print(data['topic'][4])\n",
    "print('-'*120)\n",
    "print(topic_word_dict[data['topic'][4]])\n",
    "print('-'*120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-serving-client\r\n",
      "  Downloading https://files.pythonhosted.org/packages/b5/2f/dd50af5b8dbde79e69f4bd2edec222eaa23d1015b03e9613411b78f9a639/bert_serving_client-1.9.6-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from bert-serving-client) (1.16.4)\r\n",
      "Requirement already satisfied: pyzmq>=17.1.0 in /opt/conda/lib/python3.6/site-packages (from bert-serving-client) (18.0.0)\r\n",
      "Installing collected packages: bert-serving-client\r\n",
      "Successfully installed bert-serving-client-1.9.6\r\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-serving-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from langdetect import detect,detect_langs\n",
    "from nltk import sent_tokenize\n",
    "from bert_serving.client import BertClient\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-serving-server\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/ef/0df9a6ce54a02d0a891d25af60e49b3a3a64d425e80c28acfee97f5ab0f2/bert_serving_server-1.9.6-py3-none-any.whl (61kB)\r\n",
      "\u001b[K     |████████████████████████████████| 61kB 5.1MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: termcolor>=1.1 in /opt/conda/lib/python3.6/site-packages (from bert-serving-server) (1.1.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from bert-serving-server) (1.12.0)\r\n",
      "Collecting GPUtil>=1.3.0 (from bert-serving-server)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from bert-serving-server) (1.16.4)\r\n",
      "Requirement already satisfied: pyzmq>=17.1.0 in /opt/conda/lib/python3.6/site-packages (from bert-serving-server) (18.0.0)\r\n",
      "Building wheels for collected packages: GPUtil\r\n",
      "  Building wheel for GPUtil (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\r\n",
      "Successfully built GPUtil\r\n",
      "Installing collected packages: GPUtil, bert-serving-server\r\n",
      "Successfully installed GPUtil-1.4.0 bert-serving-server-1.9.6\r\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-serving-server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'172.19.1.2'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import socket\n",
    "socket.gethostbyname(socket.gethostname())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_command = 'bert-serving-start -model_dir ../input/pretrained-bert-including-scripts/uncased_l-12_h-768_a-12/uncased_L-12_H-768_A-12 -num_worker=4'\n",
    "process = subprocess.Popen(bert_command.split(), stdout=subprocess.PIPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = BertClient(check_length=False)\n",
    "def get_embeddings(row):\n",
    "    '''Generates bert sentence embeddings.Bert server is open in the terminal.'''\n",
    "    \n",
    "    text = row['text']\n",
    "    sents = sent_tokenize(text)\n",
    "    embeddings = bert.encode(sents)\n",
    "    return embeddings\n",
    "\n",
    "data['Embeddings'] = data.apply(get_embeddings,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_centers(row):\n",
    "    ''' \n",
    "    Performs clustering of sentences in the text. Number of clusters or the number of required sentences in summary\n",
    "    is the square root of total sentences in the text.Returns cluster centers.\n",
    "    '''\n",
    "    \n",
    "    text = row['text']\n",
    "    sents = sent_tokenize(text)\n",
    "    clusters = int(np.ceil(len(sents)**0.5))\n",
    "    embeddings = row['Embeddings']\n",
    "    kmeans = KMeans(n_clusters=clusters).fit(embeddings)\n",
    "    \n",
    "    return kmeans.cluster_centers_\n",
    "\n",
    "data['Cluster Centers'] = data.apply(get_cluster_centers,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(row):\n",
    "    '''\n",
    "    Generates summary by choosing the sentences in the text that are closest to the centroid.\n",
    "    '''\n",
    "    text = row['text']\n",
    "    sents = sent_tokenize(text)\n",
    "    centroids = row['Cluster Centers']\n",
    "    embeddings = row['Embeddings']\n",
    "    clusters = centroids.shape[0]\n",
    "    sents_len = len(sents)\n",
    "    summary = []\n",
    "    for i in range(clusters):\n",
    "        select = -1\n",
    "        m = -np.inf\n",
    "        for j in range(sents_len):\n",
    "            similarity = np.dot(centroids[i],embeddings[j])\n",
    "            if similarity > m:\n",
    "                m = similarity\n",
    "                select = j\n",
    "        summary.append(select)\n",
    "    summary.sort()\n",
    "    summary = ''.join([sents[i] for i in summary])\n",
    "    return summary\n",
    "    \n",
    "data['Summary'] = data.apply(get_summary,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completely understand it   results reported lectures stand scrutiny peer  review publication convincing hope work   do aware happy risks   great important present balanced   understand move straight show promise animal study drugs humans lot animal data gather   human data gather safe effective times animal studies follow humans   major attrition points drug development unpredictability issues cladribine  gilenya   interaction predicted people   doctors patterns work on clemastine  metformin exciting   current condition personal risk tolerance makes sense it everyone\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "completely understand it   results reported lectures stand scrutiny peer  review publication convincing hope work   do aware happy risks   great important present balanced   understand move straight show promise animal study drugs humans lot animal data gather   human data gather safe effective times animal studies follow humans   major attrition points drug development unpredictability issues cladribine  gilenya   interaction predicted people   doctors patterns work on clemastine  metformin exciting   current condition personal risk tolerance makes sense it everyone\n"
     ]
    }
   ],
   "source": [
    "print(data['text'][1])\n",
    "print('-'*120)\n",
    "print(data['Summary'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"train_summary.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
